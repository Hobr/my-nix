diff --git a/whisperx/diarize.py b/whisperx/diarize.py
index 9f46b02..9e86220 100644
--- a/whisperx/diarize.py
+++ b/whisperx/diarize.py
@@ -22,7 +22,7 @@ class DiarizationPipeline:
             device = torch.device(device)
         model_config = model_name or "pyannote/speaker-diarization-3.1"
         logger.info(f"Loading diarization model: {model_config}")
-        self.model = Pipeline.from_pretrained(model_config, use_auth_token=use_auth_token).to(device)
+        self.model = Pipeline.from_pretrained(model_config, token=use_auth_token).to(device)

     def __call__(
         self,
diff --git a/whisperx/vads/pyannote.py b/whisperx/vads/pyannote.py
index 0e806bb..425111e 100644
--- a/whisperx/vads/pyannote.py
+++ b/whisperx/vads/pyannote.py
@@ -196,7 +196,7 @@ class VoiceActivitySegmentation(VoiceActivityDetection):
             **inference_kwargs,
     ):

-        super().__init__(segmentation=segmentation, fscore=fscore, use_auth_token=use_auth_token, **inference_kwargs)
+        super().__init__(segmentation=segmentation, fscore=fscore, **inference_kwargs)

     def apply(self, file: AudioFile, hook: Optional[Callable] = None) -> Annotation:
         """Apply voice activity detection
